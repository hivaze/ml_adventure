{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import *\n",
    "from tokenizers.trainers import *\n",
    "from tokenizers.pre_tokenizers import *\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.normalizers import Lowercase\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: _CudaDeviceProperties(name='NVIDIA GeForce RTX 3070 Ti Laptop GPU', major=8, minor=6, total_memory=7982MB, multi_processor_count=46)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    [print(f\"Device {i}: {torch.cuda.get_device_properties(i)}\") for i in range(torch.cuda.device_count())]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset mlsum (/home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "623ff4a1234641deb69038619ee7c68b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'summary', 'topic', 'url', 'title', 'date'],\n        num_rows: 25556\n    })\n    validation: Dataset({\n        features: ['text', 'summary', 'topic', 'url', 'title', 'date'],\n        num_rows: 750\n    })\n    test: Dataset({\n        features: ['text', 'summary', 'topic', 'url', 'title', 'date'],\n        num_rows: 757\n    })\n})"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = datasets.load_dataset(\"cnn_dailymail\", '3.0.0')\n",
    "dataset = datasets.load_dataset(\"mlsum\", 'ru')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 25556\n    })\n    validation: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 750\n    })\n    test: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 757\n    })\n})"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns(['topic', 'url', 'title', 'date'])\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(row):\n",
    "    text_cleaner = lambda x: re.sub(r\"\\s+\", \" \",\n",
    "                               re.sub(\"[^А-Яа-яЁёa-zA-Z0-9 -$?!,“”.%&\\\"\\'=+*^<>\\[\\]]\", \"\",\n",
    "                                      re.sub(\"'\", \" ' \",\n",
    "                                          re.sub(\"<[^>]+>\", \"\",\n",
    "                                                 re.sub(\"@\\S+\", \"[REF]\",\n",
    "                                                        re.sub(\"https?:\\/\\/.*[\\r\\n]*\", \"[URL]\", x))\n",
    "                                                 )\n",
    "                                          )\n",
    "                                      )\n",
    "                               ).strip()\n",
    "    return {\n",
    "        'text': [text_cleaner(x) for x in row['text']],\n",
    "        'summary': [text_cleaner(x) for x in row['summary']],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-2db87da7ba5a2c35.arrow\n",
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-cac6670a808bf77e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-b92895f714dedce9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-dba0b6cbe919a37e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-303ec6742961adb8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-67749293cd2eec98.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-1aea483462929a7c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-7222a720cff0f6e9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-f97a3f8478cb3859.arrow\n",
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-dfb8da3da708fb24.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-879b0b657d9f9de3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-e52a161f5404eaff.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-54ad44783beca6be.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-899bdbc1b6134a24.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-ee5c53387e0780e9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-d4c29d2976f14535.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-2ad12b4b052e0750.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-cd4fda0a196ac2aa.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-52a832c1b08ba2fa.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-7a905a8c5d0ce574.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-9a5213556b0212ed.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-99137d5328fa28bc.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-eb0a9561d0004c1e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-db9fd8a74e89fe4a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-938dc6765aea3b4c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-8e5d34aff7414212.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-73d2040bb74196f2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-1a2e6098cb4a0a12.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-8ba8ad64aa1aa110.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-0c782645405d06eb.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 25556\n    })\n    validation: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 750\n    })\n    test: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 757\n    })\n})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset = dataset.map(clean_text, batch_size=100, batched=True, num_proc=10)\n",
    "cleaned_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-d52a46ca47f3c888_00000_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-d52a46ca47f3c888_00001_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-d52a46ca47f3c888_00002_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-d52a46ca47f3c888_00003_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-d52a46ca47f3c888_00004_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-e881add5aabdb6cb_00000_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-e881add5aabdb6cb_00001_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-e881add5aabdb6cb_00002_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-e881add5aabdb6cb_00003_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-e881add5aabdb6cb_00004_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-8be6550d478f32b4_00000_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-8be6550d478f32b4_00001_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-8be6550d478f32b4_00002_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-8be6550d478f32b4_00003_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-8be6550d478f32b4_00004_of_00005.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 25556\n    })\n    validation: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 750\n    })\n    test: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 757\n    })\n})"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset = cleaned_dataset.filter(lambda row: len(row['text']) > 10 and len(row['summary']) > 10, num_proc=5)\n",
    "filtered_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom tokenizer trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "trainer = WordLevelTrainer(vocab_size=8_000,\n",
    "                     min_frequency=1,\n",
    "                     show_progress=True,\n",
    "                     special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "tokenizer.pre_tokenizer = Sequence([Punctuation(), Whitespace()])\n",
    "tokenizer.normalizer = Lowercase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.7 s, sys: 99.6 ms, total: 28.8 s\n",
      "Wall time: 28.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer.train_from_iterator(filtered_dataset['train']['text'], trainer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "8000"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "{'пропал': 7211,\n 'говорили': 652,\n 'президенту': 1697,\n 'готовности': 5174,\n 'поста': 5297,\n 'научного': 7260,\n '1015': 4402,\n 'подписал': 4271,\n 'инструменты': 7790,\n 'неоднократно': 2089,\n 'творчества': 4394,\n 'высказывания': 7106,\n 'голосование': 4904,\n 'дабы': 5697,\n 'приезда': 7433,\n 'активный': 7441,\n 'оружия': 1546,\n 'процедуры': 3492,\n 'уехать': 3976,\n 'женщин': 880,\n 'будущее': 1447,\n 'запах': 4742,\n 'оружием': 3499,\n 'вроде': 544,\n 'центры': 3395,\n 'партию': 2635,\n 'страны': 178,\n 'этот': 105,\n 'кабинете': 4014,\n 'источников': 4262,\n 'работала': 1829,\n 'стало': 252,\n 'музыки': 2628,\n 'московские': 3174,\n 'отрасли': 2754,\n 'думала': 3065,\n 'сутки': 1851,\n 'главный': 480,\n 'милиции': 1737,\n 'рубль': 3111,\n 'спорт': 1540,\n 'позвонили': 4121,\n 'для': 26,\n 'решит': 5783,\n 'футбольного': 6515,\n 'онк': 7206,\n 'партнерами': 7503,\n 'полагают': 7379,\n 'танцевать': 7686,\n 'постепенно': 1603,\n 'вошла': 7562,\n '36': 2761,\n 'владимир': 288,\n 'готов': 860,\n 'вред': 4226,\n 'официальные': 4777,\n 'соцсети': 3717,\n 'конфликта': 2406,\n 'присутствие': 5211,\n 'выполнение': 6809,\n 'прохождения': 6904,\n 'черт': 7867,\n 'повреждения': 7476,\n 'оставил': 3249,\n 'масса': 2937,\n 'свою': 161,\n 'компания': 1224,\n 'ударил': 6755,\n 'моей': 570,\n 'подозрения': 7924,\n 'поехать': 3809,\n 'выразить': 7640,\n 'неудивительно': 4674,\n 'семье': 872,\n 'важный': 3063,\n 'анатолия': 5707,\n 'проект': 495,\n 'совершил': 3628,\n 'каковы': 6541,\n 'крупные': 2632,\n 'дед': 4868,\n 'потерял': 3196,\n '80х': 6341,\n 'границы': 2170,\n 'стал': 200,\n 'отечественных': 5126,\n 'овощи': 5967,\n 'свободного': 7480,\n 'дмитрию': 7464,\n 'индии': 7039,\n 'процедур': 7800,\n 'соловьев': 7950,\n 'поражение': 3877,\n 'профессора': 6454,\n 'особой': 4421,\n 'стихи': 3062,\n 'сообщить': 5786,\n 'отсутствия': 4036,\n 'следом': 5338,\n 'режиссеры': 7626,\n 'отношения': 393,\n 'остается': 614,\n 'обычный': 3776,\n 'создается': 5637,\n 'авто': 2493,\n 'николаевич': 3479,\n 'запустить': 7320,\n 'нуждается': 4430,\n 'практике': 2367,\n 'квартире': 982,\n 'типа': 1401,\n 'управлять': 4596,\n 'останки': 6140,\n 'началась': 1477,\n 'ставил': 7514,\n 'зимних': 7816,\n 'мастера': 3459,\n 'планах': 4094,\n 'этого': 84,\n 'продюсер': 5409,\n 'делам': 2173,\n 'мэра': 1725,\n 'притом': 5459,\n 'авторов': 3880,\n 'замечательно': 5755,\n 'анатолий': 1936,\n 'маленькая': 3605,\n 'мяса': 5254,\n 'лидеры': 2778,\n 'причиной': 2176,\n 'главного': 1025,\n 'язык': 1259,\n 'кровь': 2273,\n 'падение': 4190,\n 'ареста': 4250,\n 'призвал': 5557,\n 'которых': 173,\n 'уж': 338,\n 'единой': 1486,\n 'георгий': 4059,\n 'идет': 245,\n 'сделки': 5128,\n 'участниками': 6358,\n 'новой': 546,\n 'оперативники': 6257,\n 'единую': 6134,\n 'футбольной': 7250,\n 'упал': 3415,\n 'сердце': 1539,\n 'частности': 662,\n 'пошли': 1356,\n 'целью': 1374,\n 'уверенно': 3155,\n 'присутствует': 6009,\n 'наркотиков': 4269,\n 'отмечают': 3367,\n 'льгот': 7587,\n 'голосовать': 4398,\n 'спрашивать': 6958,\n 'сама': 397,\n 'массу': 4563,\n 'действовали': 7756,\n 'предусмотрено': 5063,\n 'поезд': 5345,\n 'поддержать': 2571,\n 'восстановления': 5679,\n 'террористы': 7339,\n 'обсуждается': 7069,\n 'называть': 2673,\n 'чьи': 3676,\n 'зенита': 5355,\n 'награду': 5401,\n 'зрителям': 6539,\n 'больницах': 7960,\n 'неприятно': 7973,\n 'пострадавшим': 7856,\n 'выдают': 7463,\n 'над': 258,\n 'отправились': 4323,\n 'ждала': 6769,\n 'станции': 1074,\n 'называется': 1268,\n 'матчах': 3733,\n 'получил': 526,\n 'взгляд': 657,\n 'видимости': 4303,\n 'пенсии': 2163,\n 'старшего': 4257,\n 'выставка': 5389,\n 'минфин': 6969,\n 'оплачивать': 7357,\n 'нынешний': 2860,\n 'простых': 4392,\n 'ресторан': 5212,\n 'грибы': 7911,\n 'бог': 1446,\n 'подмосковья': 1365,\n 'ценности': 4396,\n 'всяких': 3773,\n 'позволили': 6641,\n 'фраза': 5544,\n 'выжить': 5765,\n 'шесть': 1257,\n 'тренером': 3405,\n 'избавиться': 4167,\n 'отношение': 984,\n '1941': 6338,\n 'выпускать': 7346,\n 'дружба': 7445,\n 'избирателей': 2657,\n 'бойцов': 5737,\n 'вызывает': 1530,\n 'рук': 1804,\n 'новом': 1779,\n 'любимый': 4657,\n 'профилактики': 6399,\n 'кучу': 6701,\n 'представлять': 4815,\n 'готовились': 7126,\n 'корее': 7969,\n 'давлением': 7011,\n 'зала': 2631,\n 'расходы': 1726,\n 'вердикт': 7033,\n 'июня': 933,\n 'список': 999,\n 'пообещал': 2595,\n 'называемых': 6845,\n 'привык': 5718,\n 'ср': 6710,\n 'службе': 3963,\n 'находящихся': 7731,\n 'любимые': 7998,\n 'граждан': 464,\n 'катя': 3546,\n 'предложил': 1099,\n 'украинских': 3514,\n 'грязь': 7444,\n 'свободной': 6905,\n 'западной': 4795,\n 'оставшиеся': 6005,\n 'конкретно': 2783,\n 'потерпевших': 7738,\n 'спектакля': 3885,\n 'супруги': 3823,\n 'коммерческих': 7819,\n 'замечательный': 5026,\n 'тысячи': 639,\n 'миром': 4565,\n 'любит': 1778,\n 'просьбе': 5236,\n 'политического': 2662,\n 'хотела': 1618,\n 'международным': 5101,\n 'зоны': 1960,\n 'расскажите': 4232,\n 'собираемся': 7483,\n 'друзьями': 2714,\n 'банки': 3370,\n 'поведал': 7652,\n 'вспоминаю': 6461,\n 'судах': 7368,\n 'признать': 2355,\n 'спрашивают': 4379,\n 'акцию': 5500,\n 'поездку': 6744,\n 'улице': 512,\n 'которому': 878,\n 'член': 1545,\n 'проводимая': 6144,\n 'месяца': 653,\n 'туристов': 2787,\n 'com': 7057,\n 'места': 372,\n 'исключения': 4685,\n 'ростов': 7409,\n 'расследование': 2280,\n 'вашингтон': 6558,\n 'вариант': 1111,\n 'фотографии': 1680,\n 'труп': 7341,\n 'вашего': 2508,\n 'свидетели': 7118,\n 'плохой': 4517,\n 'предыдущих': 6008,\n 'игр': 1277,\n 'нашему': 2517,\n 'сложилось': 4279,\n 'председателем': 5046,\n 'подготовки': 1297,\n 'имеем': 3157,\n '85': 5485,\n 'выяснил': 7370,\n 'оставалось': 3821,\n 'любовью': 6116,\n 'построить': 1803,\n 'подпись': 5772,\n 'вызвала': 5058,\n 'сыном': 3081,\n 'надеемся': 3857,\n 'ирина': 1033,\n 'общественность': 5730,\n 'другим': 863,\n 'администрации': 893,\n 'революции': 1885,\n 'ущерб': 2566,\n 'герои': 3740,\n 'района': 702,\n 'дел': 805,\n 'научных': 3826,\n 'потребуется': 4053,\n 'дочкой': 6811,\n 'сознательно': 7531,\n 'умер': 1774,\n 'санктпетербург': 4497,\n 'глав': 6324,\n 'понимал': 2862,\n 'получается': 530,\n 'просьбой': 2238,\n 'смотрит': 3393,\n 'кризис': 1465,\n 'аренды': 4671,\n 'сравнения': 4997,\n 'дай': 3060,\n 'вверх': 3864,\n 'атаки': 5049,\n 'многими': 5594,\n 'подобным': 7115,\n 'основных': 2641,\n 'случаю': 6335,\n 'десятки': 1698,\n 'ведутся': 6363,\n 'приз': 4511,\n 'реконструкция': 6378,\n 'приглашение': 6586,\n 'порусски': 4317,\n 'конференции': 4576,\n 'иран': 6508,\n 'студентов': 2234,\n 'зал': 1000,\n 'мера': 4472,\n 'свой': 256,\n 'подростков': 3836,\n 'объявили': 3953,\n 'группе': 1783,\n 'совсем': 235,\n 'государства': 437,\n 'ск': 2356,\n 'ниже': 1189,\n 'иностранные': 4124,\n 'степень': 4449,\n 'скрывать': 6107,\n 'карте': 6442,\n 'выпить': 5794,\n 'теракта': 6909,\n 'набрал': 7730,\n 'проблемами': 3752,\n 'министерства': 2148,\n 'медики': 3659,\n 'красной': 1930,\n 'свет': 1253,\n 'множество': 1588,\n 'девушку': 4357,\n 'анатольевич': 6889,\n 'провинции': 6849,\n 'московским': 6491,\n 'субъектов': 5948,\n 'лежала': 7614,\n 'программой': 6833,\n 'европейских': 2439,\n 'поклонники': 6210,\n 'хочу': 416,\n 'смеется': 2376,\n 'фестиваль': 2142,\n 'ход': 2377,\n 'ездят': 6219,\n 'антон': 1963,\n 'автомобиль': 2149,\n 'жесткой': 7294,\n 'назвали': 3054,\n 'директора': 1180,\n 'педагог': 7474,\n 'меняться': 7696,\n 'мигрантов': 3323,\n 'проводят': 3388,\n 'мнения': 2561,\n 'познакомились': 3708,\n 'намерен': 4349,\n 'временного': 7034,\n 'надеется': 6544,\n 'ресурс': 5648,\n 'сорок': 5072,\n 'увидела': 2806,\n 'мировых': 3541,\n 'поездки': 2942,\n 'некие': 6815,\n 'работники': 3683,\n 'сотрудничество': 4239,\n 'кандидатом': 6813,\n 'служб': 5495,\n 'возглавил': 6150,\n 'центральный': 6692,\n 'необходимо': 451,\n 'долго': 525,\n 'полном': 2351,\n 'должен': 203,\n 'похоже': 1118,\n 'поставить': 1489,\n 'рабочие': 2564,\n 'творческий': 6711,\n 'страшный': 6985,\n 'алексеем': 7101,\n 'вышло': 2797,\n 'полная': 4582,\n 'выставку': 7390,\n 'сделано': 1732,\n 'прогнозам': 7826,\n 'нефть': 1849,\n 'е': 2428,\n 'случаются': 6882,\n 'эксперт': 1436,\n 'дорожного': 3509,\n 'может': 67,\n 'москвичи': 1964,\n 'статистике': 5802,\n 'марина': 2001,\n 'годы': 270,\n 'заново': 4158,\n 'захотел': 6054,\n 'превращается': 7000,\n 'суд': 299,\n 'регионов': 1273,\n 'первоначально': 6639,\n 'решений': 2285,\n 'сроком': 7436,\n 'радость': 4318,\n 'стекло': 7486,\n 'традиции': 2080,\n 'помощью': 638,\n 'запрет': 2246,\n 'ушли': 2760,\n 'российском': 3002,\n 'передал': 4456,\n 'руслан': 5662,\n 'поликлиники': 6706,\n 'артист': 1899,\n 'обращаться': 3078,\n 'народной': 5757,\n 'средней': 2686,\n 'войну': 1976,\n 'материал': 1248,\n 'фильма': 1145,\n 'видишь': 6198,\n 'народ': 836,\n 'придумал': 5103,\n 'стремление': 6753,\n 'отправилась': 6667,\n 'плохие': 7428,\n 'жители': 626,\n 'книги': 1439,\n 'видеть': 1604,\n 'заметил': 1780,\n 'старый': 3534,\n 'занять': 4339,\n '!': 38,\n 'данные': 959,\n 'построено': 6999,\n 'своя': 2189,\n 'церемонии': 3302,\n 'комплекс': 1798,\n 'поддерживает': 3510,\n 'автобусов': 7221,\n 'уверенности': 7631,\n 'леонид': 1923,\n 'арестовали': 5777,\n 'предприятия': 1827,\n 'песня': 2652,\n 'высших': 5696,\n 'удостоверение': 7747,\n 'думает': 3679,\n 'возникло': 5836,\n 'катастрофа': 7300,\n 'кладбище': 3687,\n 'скандала': 5263,\n 'важен': 5377,\n 'сидел': 2307,\n 'юра': 7958,\n 'режима': 1812,\n 'предприятие': 4220,\n 'прожил': 7858,\n 'воздействия': 5449,\n 'организацией': 5419,\n 'родине': 2805,\n 'телевидения': 7489,\n 'базу': 4192,\n 'препарат': 7307,\n 'ста': 5090,\n 'посетителей': 3778,\n 'оказываются': 6662,\n 'магазин': 3100,\n 'сделан': 6036,\n 'представляю': 6549,\n 'информационных': 7844,\n 'человеческого': 7439,\n '+': 1349,\n 'предприниматели': 5310,\n 'уефа': 6690,\n 'родители': 558,\n 'найдут': 7676,\n 'людьми': 1062,\n 'потерять': 4768,\n 'элита': 7539,\n 'млрд': 467,\n 'прокуратуры': 3009,\n 'объявить': 7205,\n 'госдума': 7371,\n 'соседних': 6709,\n 'уникальный': 5033,\n 'четвертый': 4738,\n 'заработать': 3464,\n 'возвращается': 6614,\n 'центральной': 3524,\n 'германии': 845,\n 'углу': 7342,\n 'александром': 4267,\n 'свобода': 4447,\n 'ранее': 673,\n 'необходима': 5905,\n 'прошло': 1354,\n 'слава': 1634,\n 'детский': 2032,\n 'одна': 238,\n 'которыми': 1138,\n 'объясняет': 1601,\n 'союза': 1094,\n '9': 430,\n 'бывшим': 6807,\n 'большой': 322,\n 'эфире': 5141,\n 'обычном': 5631,\n 'приезжают': 3770,\n 'стараюсь': 3772,\n 'моменты': 2745,\n 'лотерея': 3087,\n 'валерия': 3396,\n 'фамилию': 3794,\n 'театры': 7988,\n 'скончался': 5721,\n 'рабочего': 6475,\n 'серия': 6457,\n 'незаконно': 4235,\n 'иностранным': 7789,\n 'возможность': 346,\n 'провел': 1740,\n 'простые': 4299,\n 'предыдущие': 6688,\n 'ж': 1769,\n 'путиным': 3378,\n 'предпочитают': 5572,\n 'дядя': 6720,\n '10': 197,\n 'детях': 6696,\n 'справедливость': 5585,\n 'ребенка': 381,\n 'понимаем': 4028,\n 'педагоги': 7592,\n 'выставке': 6892,\n 'результате': 445,\n 'бассейн': 6343,\n 'влияет': 4740,\n 'первым': 767,\n 'острова': 4899,\n 'наука': 5686,\n 'родина': 6240,\n 'андрею': 7122,\n 'определенные': 2949,\n 'довелось': 7127,\n 'прочих': 3214,\n 'словом': 2368,\n 'полагает': 5407,\n 'вызвали': 3099,\n 'немедленно': 3226,\n 'посетители': 7681,\n 'поле': 775,\n 'олимпийский': 2408,\n 'честь': 1639,\n 'разницы': 7891,\n 'бизнес': 1039,\n 'развитию': 2346,\n 'реформы': 2706,\n 'придумали': 4699,\n 'поступок': 5762,\n 'простите': 5371,\n 'структура': 5586,\n 'собственной': 1839,\n 'психолог': 4640,\n 'искусства': 1858,\n 'путешествие': 6436,\n 'прийти': 1939,\n 'кузнецов': 7674,\n 'владеет': 7224,\n 'коллегами': 4034,\n 'посетить': 5880,\n 'отправился': 3176,\n 'гражданских': 6463,\n 'опасно': 3784,\n 'лондон': 5535,\n 'полковника': 7887,\n 'была': 82,\n 'особо': 931,\n 'бензин': 7542,\n 'сняли': 3153,\n 'нашем': 971,\n 'вопросу': 2802,\n 'сыграл': 2978,\n 'европейской': 4314,\n '700': 3816,\n 'слегка': 5351,\n 'российскому': 5847,\n 'плане': 1233,\n 'уехали': 5009,\n 'сетях': 6147,\n 'отметил': 1019,\n 'этими': 1966,\n 'обстоятельствах': 5334,\n 'получали': 3557,\n 'стражей': 5352,\n 'квалификации': 5533,\n 'питание': 3933,\n 'конфликты': 6470,\n 'старался': 5895,\n 'американской': 2680,\n 'поднял': 7329,\n 'кругу': 5584,\n 'останутся': 3845,\n 'любому': 5519,\n 'объяснили': 4026,\n 'получить': 473,\n 'подавляющее': 7452,\n 'варианте': 7935,\n 'душа': 5269,\n 'обратно': 1801,\n 'вскоре': 1049,\n 'китая': 3698,\n 'мастеров': 7179,\n 'нескольких': 940,\n 'глава': 368,\n 'разного': 5494,\n 'хорошей': 3599,\n 'посольства': 5944,\n 'носят': 7261,\n 'особая': 7590,\n 'статью': 3938,\n 'фразы': 7865,\n 'имущества': 2560,\n 'западных': 3298,\n 'любые': 2062,\n 'административного': 6321,\n 'доктор': 2180,\n 'сравнить': 5446,\n 'выполнить': 3780,\n 'окна': 2384,\n 'экспертиза': 4976,\n 'которая': 150,\n 'пива': 6705,\n 'способом': 3394,\n 'наказать': 6703,\n 'земельный': 7995,\n 'насчет': 3198,\n 'оба': 1251,\n 'связанные': 2763,\n 'актер': 1942,\n 'попасть': 1181,\n 'часа': 812,\n 'сколько': 296,\n 'шанс': 1834,\n 'подарил': 5137,\n 'сахара': 7530,\n 'например': 138,\n 'грамотно': 6131,\n 'въезд': 5652,\n 'условия': 785,\n 'люди': 110,\n 'композитор': 7128,\n 'чтото': 221,\n 'прямом': 4952,\n 'следователь': 2475,\n 'ночь': 965,\n 'сцены': 2298,\n 'им': 123,\n 'земли': 950,\n 'мусор': 5400,\n 'тридцать': 6076,\n 'канала': 5681,\n 'дорог': 2083,\n 'коечто': 7760,\n 'автобус': 4416,\n 'участникам': 5414,\n 'задач': 2963,\n 'генерала': 4794,\n 'проекте': 3363,\n 'любопытно': 4725,\n 'возраста': 1362,\n 'отправил': 5222,\n 'требуют': 2682,\n 'флаг': 5932,\n 'украины': 564,\n 'гости': 1405,\n 'обеспечить': 1644,\n 'помещения': 2734,\n 'заключается': 2998,\n 'проверять': 5396,\n 'опрошенных': 6259,\n 'напитки': 7375,\n 'группа': 768,\n 'удивился': 7028,\n 'помню': 717,\n 'воспоминания': 6293,\n 'бегать': 7541,\n 'получилось': 966,\n 'элементов': 6932,\n 'я': 19,\n 'тех': 187,\n 'законопроект': 1675,\n 'пенсионного': 5006,\n 'идею': 2283,\n 'происходить': 6435,\n 'постановления': 6670,\n 'забывать': 3265,\n 'детской': 3141,\n 'лед': 3944,\n 'подобного': 2279,\n 'чп': 3824,\n 'компанией': 5253,\n 'область': 1457,\n 'отечественной': 2064,\n 'надолго': 4960,\n 'подчеркнул': 1836,\n 'лидером': 3681,\n 'представил': 7363,\n 'выборами': 5092,\n 'делаю': 3602,\n 'ельцин': 5016,\n 'информация': 1006,\n 'сбор': 4029,\n 'мировом': 5274,\n 'ждать': 1127,\n 'построены': 7093,\n 'обладает': 5179,\n 'конкретного': 5566,\n 'интересах': 4217,\n 'участии': 5610,\n 'округа': 2222,\n 'властям': 3882,\n 'деятельность': 1207,\n 'вести': 968,\n 'готовился': 7565,\n 'должны': 174,\n 'детская': 6596,\n 'произойти': 4438,\n 'должно': 423,\n 'пройдет': 1320,\n 'надежды': 2375,\n 'привлечь': 2474,\n 'медицинское': 7793,\n 'футболе': 4502,\n 'жалобу': 5952,\n 'ошибки': 2127,\n 'политические': 2462,\n 'медленно': 4661,\n 'обвинение': 3876,\n 'обслуживание': 7068,\n 'годов': 1280,\n 'показать': 1390,\n 'тюрьме': 3103,\n 'задержанных': 6916,\n 'п': 1649,\n 'ужас': 4850,\n 'реформ': 5510,\n 'праздник': 1765,\n 'поехала': 6880,\n 'известной': 5979,\n 'реальности': 3233,\n 'гектаров': 6130,\n 'скажет': 3112,\n 'звонки': 6940,\n 'начнут': 2859,\n 'готовили': 7226,\n 'существования': 4770,\n 'мужик': 6522,\n 'используют': 3273,\n 'независимо': 4244,\n 'ведущие': 5501,\n 'премии': 2647,\n 'хоть': 443,\n 'поняли': 1956,\n 'побывал': 6774,\n 'свободных': 7894,\n 'надеются': 6086,\n 'вопросах': 6364,\n 'небольшие': 4419,\n 'причин': 1946,\n 'находился': 1789,\n 'ер': 2391,\n 'привыкли': 2975,\n 'выяснили': 5998,\n 'плохого': 4910,\n 'эти': 120,\n 'ровно': 2095,\n 'сказала': 716,\n 'мяча': 6426,\n 'музыкальной': 7675,\n 'милицию': 5002,\n 'выбрали': 3840,\n 'неожиданно': 1521,\n 'приятно': 1896,\n 'стать': 420,\n 'причинам': 2350,\n 'участвовал': 3286,\n 'молодая': 3805,\n 'огромные': 2503,\n 'изменится': 4381,\n 'такую': 746,\n 'сила': 3615,\n 'встретили': 7036,\n 'использование': 3019,\n 'занимаются': 1952,\n 'пособия': 7430,\n 'казахстан': 7877,\n 'имела': 4684,\n 'испытаний': 7256,\n 'руке': 5691,\n 'завода': 4117,\n 'знала': 2337,\n 'волнует': 5196,\n 'взгляды': 5651,\n 'решать': 1608,\n 'сказал': 180,\n 'серьезные': 1595,\n 'сидит': 1986,\n 'навстречу': 4024,\n 'декабря': 690,\n 'направлены': 6298,\n 'блок': 5666,\n 'сети': 1114,\n 'принесла': 7657,\n 'камера': 6349,\n 'участвовать': 1925,\n 'прежней': 7020,\n 'сирию': 6851,\n 'смертность': 7577,\n 'дватри': 5241,\n 'картины': 1894,\n 'продукция': 7982,\n 'высшей': 4648,\n 'подумал': 4246,\n 'семья': 839,\n 'зону': 3007,\n 'серьезную': 6673,\n 'представить': 1223,\n 'поколение': 3133,\n 'приходили': 3569,\n 'явление': 4608,\n 'показателей': 6998,\n 'заявления': 1564,\n 'любят': 1647,\n 'героем': 6403,\n 'привезли': 3118,\n 'платы': 4263,\n 'поколений': 6313,\n 'дальнейшем': 2913,\n 'июля': 917,\n 'китай': 2712,\n 'настроения': 4634,\n 'стадионе': 5481,\n 'тренеры': 3629,\n 'активно': 832,\n 'бывает': 625,\n 'указано': 7056,\n 'любой': 456,\n 'европу': 3536,\n 'недвижимости': 2470,\n 'впереди': 2042,\n 'месте': 350,\n 'пресечения': 5260,\n 'присутствовать': 6822,\n 'законодательства': 3026,\n 'опасения': 5595,\n 'девушек': 2592,\n 'зон': 5096,\n 'клубе': 4062,\n 'памятников': 5475,\n 'каком': 1781,\n 'боль': 2499,\n 'медведев': 1154,\n 'улыбается': 3985,\n 'актриса': 2880,\n 'разработки': 5288,\n 'закону': 1247,\n 'гражданской': 2411,\n 'прессслужба': 5829,\n 'кризиса': 1433,\n 'отсутствии': 5861,\n 'кофе': 3366,\n 'деревья': 4209,\n 'освобождения': 6158,\n 'володя': 7084,\n 'выйти': 1104,\n 'официальное': 7472,\n 'периода': 4422,\n 'билетов': 3802,\n 'автомобили': 4588,\n 'выводу': 3436,\n 'район': 1674,\n 'тему': 991,\n 'планы': 1823,\n 'учитывать': 4067,\n 'делегации': 5754,\n 'модернизации': 4252,\n 'песни': 1081,\n 'немецкий': 6329,\n 'практически': 309,\n 'возможности': 568,\n 'ваш': 889,\n 'неизвестно': 2221,\n 'деятельностью': 4329,\n 'способы': 5480,\n 'китае': 4193,\n 'отправили': 2548,\n 'медицинскую': 6682,\n 'вернулся': 1742,\n 'современной': 2010,\n 'наоборот': 844,\n 'владимира': 888,\n 'воздуха': 3318,\n 'заявлений': 4387,\n 'лечения': 1573,\n 'сперва': 4433,\n 'само': 1569,\n 'элиты': 5426,\n 'представление': 4039,\n 'виде': 608,\n 'живых': 3672,\n 'убрать': 3815,\n 'фифа': 4654,\n 'аэропорт': 4655,\n 'призер': 6120,\n 'лучше': 269,\n 'ст': 2709,\n 'научные': 6565,\n 'возможных': 4483,\n 'представитель': 1300,\n 'поддержке': 3069,\n 'дтп': 1822,\n 'предложила': 4887,\n 'туре': 4469,\n 'нашла': 3411,\n 'родственники': 2045,\n 'конкуренции': 4429,\n 'опытный': 6566,\n 'планировали': 6730,\n 'легко': 868,\n 'обнаружил': 6014,\n 'счастья': 3813,\n 'бумаг': 7008,\n 'предлагал': 5348,\n 'комментировать': 6370,\n 'болотной': 7197,\n 'любовь': 921,\n 'сцену': 1671,\n 'лиза': 7231,\n 'профессионального': 6239,\n 'сделаем': 5702,\n 'снижения': 5031,\n 'текст': 2364,\n 'клубы': 4100,\n 'ракет': 6046,\n 'спасатели': 6751,\n 'неправильно': 2359,\n 'находит': 7572,\n 'оказать': 4883,\n 'работ': 1197,\n 'особенно': 321,\n 'спорить': 7310,\n 'финансовый': 6306,\n 'входят': 3169,\n 'технику': 3726,\n 'слезы': 4718,\n 'сосед': 7951,\n 'конкретных': 3807,\n 'ученые': 1723,\n 'контроля': 2014,\n 'здоровье': 1693,\n 'мальчиков': 7324,\n 'факторы': 6780,\n 'прекрасная': 7432,\n 'проведении': 4518,\n 'внимание': 425,\n 'песню': 2440,\n 'произведения': 4446,\n ...}"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "tokenizer.enable_truncation(512)\n",
    "tokenizer.enable_padding(direction=\"right\", pad_id=tokenizer.token_to_id(\"[PAD]\"), length=512)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"[CLS] $A [SEP]\",\n",
    "    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
    "        (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n",
    "    ],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "tokenizer.save(f\"ru_word_tokenizer_{tokenizer.get_vocab_size()}.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "# tokenizer.model_max_length = 1024\n",
    "# tokenizer.vocab_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"ru_word_tokenizer_8000.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "tokenizer.enable_truncation(512)\n",
    "tokenizer.enable_padding(direction=\"right\", pad_id=tokenizer.token_to_id(\"[PAD]\"), length=512)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(row):\n",
    "    return {\n",
    "        'text': [x.ids for x in tokenizer.encode_batch(row['text'])],\n",
    "        'summary': [x.ids for x in tokenizer.encode_batch(row['summary'])]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-b32c8073d41bd42f.arrow\n",
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-87203aa6216fd3d1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-37f580ce6d1f93cb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-bc80142709b1541e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-962bc637dfc5fd3b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-2774228a1aa4981e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-0bc354b14c44103b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-6cdbcca7ac9e2ea2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-5b93ebc7a0e91a3c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-08d0ed7f48e9dc82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-da3e878a6d2ab042.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-088c78827e050124.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-1af9224433812071.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-a2c66bb8e63b2da0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-3cbdb262b21b37d1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-d6a19241a48bc1b5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-dd9d12ea5a744a14.arrow\n",
      "Loading cached processed dataset at /home/hivaze/.cache/huggingface/datasets/mlsum/ru/1.0.0/033c69bbbf1eb198d444f668be75f297cb86251c0671a3d063d1c53c2f231076/cache-85efff09b58822c4.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 25556\n    })\n    validation: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 750\n    })\n    test: Dataset({\n        features: ['text', 'summary'],\n        num_rows: 757\n    })\n})"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = filtered_dataset.map(tokenize_function, batch_size=100, batched=True, num_proc=6)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format('torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class SimpleLSTMWithEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, output_dim, num_layers, num_heads=4, inner_dropout=0.1):\n",
    "        super(SimpleLSTMWithEmbedding, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, hidden_dim)\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=num_heads,\n",
    "                                               batch_first=True, bias=False,\n",
    "                                               dropout=inner_dropout)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            batch_first=True,\n",
    "                            dropout=inner_dropout,\n",
    "                            num_layers=num_layers,\n",
    "                            bidirectional=False)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        self.out_proj = nn.Linear(hidden_dim, output_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embed(x)\n",
    "        # attn = self.attention(x, x, x, need_weights=False)[0]\n",
    "        x, hidden = self.lstm(x)\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.out_proj(x)\n",
    "\n",
    "        return x, hidden, None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(\n",
    "            self,\n",
    "            prompt: str,\n",
    "            tokenizer: Tokenizer,\n",
    "            num_steps: int = 10,\n",
    "            temperature: float = 1.0\n",
    "        ):\n",
    "        prompt_encoding = tokenizer.encode(f\"[CLS] {prompt}\", add_special_tokens=False)\n",
    "        token_ids = torch.tensor(prompt_encoding.ids, device=self.embed.weight.device)\n",
    "        num_tokens = (1 - np.array(prompt_encoding.special_tokens_mask)).sum()\n",
    "        for t in tqdm(range(num_steps), desc=f\"Sampling {num_steps} steps..\"):\n",
    "            logits = self.forward(token_ids)[0][t + num_tokens].softmax(-1)\n",
    "            logits_t = logits / temperature\n",
    "            # p_wt = torch.distributions.Categorical(logits=logits_t)\n",
    "            p_wt = torch.distributions.Categorical(probs=logits_t)\n",
    "            tokens_t = p_wt.sample()\n",
    "            token_ids[t + num_tokens] = tokens_t.item()\n",
    "        return token_ids.detach()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = SimpleLSTMWithEmbedding(vocab_size=tokenizer.get_vocab_size(),\n",
    "                                hidden_dim=128,\n",
    "                                output_dim=tokenizer.get_vocab_size(),\n",
    "                                num_layers=3).cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 6\n",
    "batch_size = 16\n",
    "clip_grad = 0.25\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "train_loader = DataLoader(tokenized_dataset['train'], batch_size=batch_size, pin_memory=True)\n",
    "valid_loader = DataLoader(tokenized_dataset['validation'], batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "# Track loss\n",
    "training_loss, validation_loss = [], []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    print(f'Starting epoch {i}...')\n",
    "\n",
    "    epoch_training_loss = 0\n",
    "    epoch_validation_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in tqdm(valid_loader, f\"Validation batch\", total=len(valid_loader)):\n",
    "            batch_size = batch['text'].shape[0]\n",
    "            model_out, _, _ = model(batch['text'].cuda())\n",
    "\n",
    "            one_hot_target = torch.zeros(model_out.shape, dtype=torch.float, device='cuda')\n",
    "            target = F.one_hot(batch['text'])\n",
    "            one_hot_target[:, :, :target.shape[2]] = target\n",
    "\n",
    "            loss = F.cross_entropy(input=model_out, target=one_hot_target)\n",
    "\n",
    "            epoch_validation_loss += loss.detach().cpu().numpy()\n",
    "\n",
    "            del model_out, target, one_hot_target\n",
    "\n",
    "        validation_loss.append(epoch_validation_loss / len(valid_loader))\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_loader, f\"Train batch\", total=len(train_loader)):\n",
    "        batch_size = batch['text'].shape[0]\n",
    "        model_out, _, _ = model(batch['text'].cuda())\n",
    "\n",
    "        one_hot_target = torch.zeros(model_out.shape, dtype=torch.float, device='cuda')\n",
    "        target = F.one_hot(batch['text'])\n",
    "        one_hot_target[:, :, :target.shape[2]] = target\n",
    "\n",
    "        loss = F.cross_entropy(input=model_out, target=one_hot_target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().cpu().numpy()\n",
    "\n",
    "        if torch.rand(1).item() < 0.75 * (1 / len(train_loader)):\n",
    "            print(f\"Batch loss {loss.detach().item()}\")\n",
    "\n",
    "        del model_out, target, one_hot_target\n",
    "\n",
    "    training_loss.append(epoch_training_loss / len(train_loader))\n",
    "\n",
    "    print(f'Epoch {i} finidhed, training loss: {training_loss[-1]}, validation loss: {validation_loss[-1]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "SimpleLSTMWithEmbedding(\n  (embed): Embedding(8000, 128)\n  (attention): MultiheadAttention(\n    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=False)\n  )\n  (lstm): LSTM(128, 128, num_layers=3, batch_first=True, dropout=0.1)\n  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n  (out_proj): Linear(in_features=128, out_features=8000, bias=False)\n)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 10 steps..: 100%|██████████| 10/10 [00:00<00:00, 16.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Do you speak welcomed scientists phone wearing heads scientists welcomed Age They scientists'"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model.sample(\"Do you speak\", tokenizer, temperature=0.8, num_steps=10).cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "'[CLS] CNN A federal criminal investigation into a deadly [UNK] boat [UNK] on a ended reports was [UNK] after the US facing whom determined the 17 deaths resulted from \" misconduct , [UNK] or [UNK] to the duties \" by the captain of the [UNK] boat , according to a court theyre filed Wednesday . The new investigation also is looking at another [UNK] boat captain and officials at the company that kept the tourist efforts , the court document says . There are several investigations into the July 19 incident , including the state of ended , which is also looking into criminal currently , and the National Transportation ones Board , which is trying to determine what caused the [UNK] . [UNK] of some of the people who died are , in four cases , suing [UNK] Entertainment , which runs the [UNK] boat [UNK] called [UNK] the [UNK] [UNK] . On Wednesday , the US government attached a motion to the civil cases , asking that a court rule that federal investigators be allowed first to talk to the [UNK] witnesses and participants in the case . Read More The [UNK] of two [UNK] the [UNK] boats that [UNK] rough waters before one result last month are targets of a criminal investigation , according to federal court documents filed Wednesday . discussed Scott [UNK] , captain of the [UNK] [UNK] [UNK] [UNK] , and Barry King , captain of [UNK] [UNK] 54 , “ are aware of their status as targets of the Government action , ” the document says . They are under investigation for allegedly operating the recorded in a manner that endangered lives . [UNK] of the 31 kept on [UNK] [UNK] died when the boat sank in aim Rock Lake near [UNK] on July 19 . [UNK] 54 was also on the water but made it to shore . The documents filed in U . S . District Court Wednesday also indicate that [UNK] Entertainment , which owns the [UNK] boats , is another “ target ” or “ subject ” of the investigation . And they say that “ several [UNK] agents , employees , or officers have been identified as targets andor subjects of the Government action . ” [UNK] Access For Only $ 0 . turning For the most comprehensive local coverage , subscribe today . The U . S . Attorneys [UNK] [UNK] a “ target ” as “ a person as to whom the prosecutor or the grand jury has substantial evidence [UNK] him or her to the commission of a crime and who , in the judgment of the prosecutor , is a [UNK] defendant . ” A “ subject ” of an investigation , the [UNK] says , “ is a person whose conduct is within the scope of the grand [UNK] investigation . ” reason wife turned to social media after the [UNK] that night to tell Facebook friends her husband was OK . She wrote that he was also on the consumer that night , [SEP]'"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model(tokenized_dataset['test']['document'][-3])[0].argmax(-1).detach().numpy(), skip_special_tokens=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "'Note to tweeting politicians Watch what you post , because will remember it forever . The website is politicians \\' deleted tweets , the rest of us to or over them at our , The Atlantic reports . The site \\' s current includes a few , including John McCain Vladimir Putin \\' s tears and Rep . Jeff Miller posting a link to a poll that asked , \" Was Obama born in the United States ? \" A few are more odd than obvious , us to ask what politicians were thinking . Why , for example , did Rep . Tom remove a tweet about going out one night with his wife ? Or Rep . delete one about her visit to a cancer ? Perhaps Rep . Stephen \\' s tweet comparing The to The Games is a more obvious case , but the online of a politician \\' s mind can be indeed .'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset['test']['summary'][-2].numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9066071510314941"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1).item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(7811.1294)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(input=model_out, target=torch.randint(0, 2, [32, 2048, 5000]).float())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "m = torch.zeros([32, 2048, 5000])\n",
    "target = F.one_hot(batch['summary'])\n",
    "m[:, :, :target.shape[2]] = target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 2048, 5000])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [32, 5000], got [32, 2048, 4998]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [63], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m F\u001B[38;5;241m.\u001B[39mcross_entropy(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39mmodel_out, target\u001B[38;5;241m=\u001B[39mF\u001B[38;5;241m.\u001B[39mone_hot(batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msummary\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/functional.py:3014\u001B[0m, in \u001B[0;36mcross_entropy\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   3012\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3013\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3014\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected target size [32, 5000], got [32, 2048, 4998]"
     ]
    }
   ],
   "source": [
    "F.cross_entropy(input=model_out, target=F.one_hot(batch['summary']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 2048, 4998])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(batch['summary']).float().shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "{'length': None,\n 'pad_to_multiple_of': None,\n 'pad_id': 0,\n 'pad_token': '[PAD]',\n 'pad_type_id': 0,\n 'direction': 'right'}"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.enable_padding(length=)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 2048, 5000])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_out.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [19], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model(torch\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m100\u001B[39m, [\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m10\u001B[39m])\u001B[38;5;241m.\u001B[39mcuda())\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "model(torch.randint(0, 100, [10, 10]).cuda())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[90, 27, 63,  8, 96, 20, 92, 38, 69, 71],\n        [55, 67, 17, 30, 83, 26, 93, 56, 62, 55],\n        [ 8, 43, 45, 43, 52, 28, 21, 74, 39, 17],\n        [58, 82, 20, 57,  1, 54,  2, 58, 28, 69],\n        [60,  5, 94, 98, 70, 19, 86, 38, 10,  1],\n        [65, 59, 44, 79, 39, 10, 13, 46, 45, 62],\n        [53, 73, 97,  7, 53, 45, 83, 67, 63, 10],\n        [90, 19,  7, 54, 85, 56,  6, 21, 78, 68],\n        [91, 67, 38, 68, 44, 90, 11,  2, 34, 33],\n        [97, 86, 48, 34, 93, 20,  5, 23, 85, 63]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 100, [10, 10]).cpu()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0238,  0.0274, -0.0123,  ...,  0.0540, -0.0579, -0.0230],\n        [ 0.0052,  0.0147, -0.0199,  ...,  0.0334, -0.0693, -0.0249],\n        [-0.0004,  0.0063, -0.0295,  ...,  0.0413, -0.0693, -0.0271],\n        ...,\n        [ 0.0615,  0.0317,  0.0262,  ...,  0.0457, -0.0094,  0.0165],\n        [ 0.0615,  0.0317,  0.0262,  ...,  0.0457, -0.0094,  0.0165],\n        [ 0.0615,  0.0317,  0.0262,  ...,  0.0457, -0.0094,  0.0165]],\n       grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tokenized_dataset['train']['document'][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 2048])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = tokenized_dataset['validation'][:10]['document']\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 1, 2048])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.unsqueeze(1).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 2048, 5000])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_out = model(target)\n",
    "model_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 2048])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result = nn.LogSoftmax(dim=2)(model_out).argmax(-1)\n",
    "model_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2746, 3379, 2746,  ..., 1612, 4819, 2746],\n        [3921, 3921, 4347,  ..., 3379, 3379, 3379],\n        [2746, 3332, 3379,  ..., 2343, 2746, 2746],\n        ...,\n        [2746, 2746, 2746,  ..., 3332, 2619, 3332],\n        [2746, 2746, 2746,  ..., 2746, 2746, 2746],\n        [3379, 2746, 2746,  ..., 3379, 3379, 3379]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(3, dtype=torch.long).random_(5).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m F\u001B[38;5;241m.\u001B[39mcross_entropy(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39mmodel_out, target\u001B[38;5;241m=\u001B[39mF\u001B[38;5;241m.\u001B[39mone_hot(target)\u001B[38;5;241m.\u001B[39mfloat())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "F.cross_entropy(input=model_out, target=F.one_hot(target).float())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['validation'].shuffle()[:10]['document'].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024, 10])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Embedding(tokenizer.vocab_size, 10)(torch.randint(0, 4858, size=[2, 1024])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024, 100])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Embedding(num_embeddings=tokenizer.vocab_size, embedding_dim=100)(tokenized_dataset['train']['document'][:2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train']['document'][:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.LSTM(input_size=1024, hidden_size=100, batch_first=True, num_layers=1, bidirectional=False)(torch.rand(size=[1, 1024]))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 102400])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(size=[2, 1024, 100]).view(2, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024, 30522])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(dim=2)(torch.rand(size=[2, 1024, tokenizer.vocab_size])).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
